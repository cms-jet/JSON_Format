import pandas as pd
import numpy as np
from collections import OrderedDict
from correctionlib.schemav2 import Correction, Binning, Category, Formula, CorrectionSet
import os, sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import helperfunctionsv2 as hf
import gzip
import ROOT

bprintouts=False

###
#
# This script, does not yet provid an uncertainty. The syst 'up'/'down' will just be the nominal value
#
###

def create_corr(year):
    infile = "puppiCorr.root"
    
    inputFile = ROOT.TFile.Open(infile)
    

    histname_central = "puppiJECcorr_reco_0eta1v3"
    histname_forward = "puppiJECcorr_reco_1v3eta2v5"
    histname_gen = "puppiJECcorr_gen"

    hist_central = inputFile.Get(histname_central)
    hist_forward = inputFile.Get(histname_forward)
    hist_gen = inputFile.Get(histname_gen)

    print(hist_central.GetTitle())
    print(hist_central.GetParameter(0))
    print(hist_central.GetNpar())
    # GetNpar
    # loop over and replace in the string, don't forget brackekt , multiply and create a new TF1
    print(hist_gen.GetTitle())
    
    
    dataInfo = OrderedDict()
    if "2016" in year:
        dataInfo['etaMin'] = ['-2.4','-1.3','1.3']
        dataInfo['etaMax'] = ['-1.3','1.3','2.4']
    else:
        dataInfo['etaMin'] = ['-2.5','-1.3','1.3']
        dataInfo['etaMax'] = ['-1.3','1.3','2.5']

    dataInfo['ptMin'] = [170 for el in dataInfo['etaMin']]
    dataInfo['ptMax'] = [float('inf') for el in dataInfo['etaMin']]

    dataInfo['corr'] = [hist_forward,hist_central,hist_forward]
    dataInfo['corr_gen'] = [hist_gen,hist_gen,hist_gen]
    dataInfo['formula'] = [hist_forward,hist_central,hist_forward]

    print(dataInfo['corr'][0].Eval(300)* dataInfo['corr_gen'][0].Eval(300))

    df = pd.DataFrame( dataInfo )
    df['ptMin'] = df['ptMin'].astype(int)
    df['ptMax'] = df['ptMax'].astype(int)
    df['etaMin'] = df['etaMin'].astype(float)
    df['etaMax'] = df['etaMax'].astype(float)
    
    corr_softdrop_part = Correction.parse_obj(
        {
            "version": 1,
            "name": "JMS",
            "description": "SoftDrop mass scale correction",
            "inputs": [
                {"name": "eta", "type": "real", "description": "eta of the jet"},
                {"name": "pt", "type": "real", "description": "pT of the jet"},
                {"name": "systematic", "type": "string", "description": "systematics: nom, up, down"},
               
            ],
            "output": {"name": "weight", "type": "real"},
            "data": hf.build_systs_formular(df,False),
    }
        )
    
    if bprintouts: print(corr_softdrop_part)


    cset = CorrectionSet.parse_obj({
    "schema_version": 2,
        "corrections": [
        corr_wtagging_part    ]
    })
    cset.json()
    with open(year_+'_softdrop.json', "w") as fout:
        fout.write(cset.json(exclude_unset=True, indent=4))
        
    
        
create_corr("2016")
create_corr("2017")
create_corr("2018")

from correctionlib import _core

#Download the correct JSON files 
evaluator = _core.CorrectionSet.from_file('2016_softdrop.json')

valsf= evaluator["JMS"].evaluate(1.0,200.,"nom")
print("sf is:"+str(valsf))

valsf= evaluator["JMS"].evaluate(1.0,200.,"up")
print("sf up is:"+str(valsf))

valsf= evaluator["JMS"].evaluate(1.0,200.,"down")
print("sf down is:"+str(valsf))

